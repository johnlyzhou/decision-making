{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adeb008",
   "metadata": {},
   "source": [
    "# Featurize processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79953339",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"/Users/johnzhou/research/decision-making\"\n",
    "expt_dir = f\"{repo_path}/experiments\"\n",
    "data_dir = f\"{repo_path}/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7144e9",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c977cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b548b8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "\n",
    "from src.utils import normalize_features\n",
    "\n",
    "from src.data.blocks import RealDataset, SynthDataset\n",
    "from src.models.agentnet import AgentNet\n",
    "from src.models.sigmoidnet import SigmoidNet\n",
    "from src.models.train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976b27d",
   "metadata": {},
   "source": [
    "Sigmoid fitting with MSE loss seems to be empirically more sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03c9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = \"unbounded_a\"\n",
    "\n",
    "config = OmegaConf.create({\n",
    "    \"name\": expt_name,\n",
    "    \"random_seed\": 4995,\n",
    "    \"model\": {\n",
    "        \"in_features\": 19,\n",
    "        \"linear_layers\": [32, 8, 4],\n",
    "        \"use_batch_norm\": False\n",
    "    },\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"data\": {\n",
    "        \"feature_path\": f\"{data_dir}/processed/{expt_name}/synth_feats.npy\",\n",
    "        \"label_path\": f\"{data_dir}/processed/{expt_name}/synth_labels.npy\",\n",
    "        \"train_proportion\": 0.8,\n",
    "        \"train_batch_size\": 64,\n",
    "        \"val_batch_size\": 64\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 0,\n",
    "        \"max_epochs\": 1000\n",
    "    },\n",
    "\n",
    "})\n",
    "\n",
    "OmegaConf.save(config=config, f=f\"{repo_path}/configs/model_configs/sigmoidnet_train.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad76c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d4411880afbb5f49\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d4411880afbb5f49\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=$expt_dir/$expt_name/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a327be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearEmbedder(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=19, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.05)\n",
      "    (2): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.05)\n",
      "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.05)\n",
      "    (6): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /Users/johnzhou/research/decision-making/experiments/unbounded_a exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name  | Type           | Params\n",
      "-----------------------------------------\n",
      "0 | loss  | SupConLoss     | 0     \n",
      "1 | model | LinearEmbedder | 950   \n",
      "-----------------------------------------\n",
      "950       Trainable params\n",
      "0         Non-trainable params\n",
      "950       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  72%|████████████▎    | 100/138 [00:00<00:00, 226.68it/s, loss=4.27, v_num=1]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                              | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  87%|██████████████▊  | 120/138 [00:00<00:00, 218.61it/s, loss=4.27, v_num=1]\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████████▍      | 20/28 [00:00<00:00, 217.94it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 138/138 [00:00<00:00, 204.98it/s, loss=4.33, v_num=1, val_loss=4.300]\u001b[A\n",
      "Epoch 1:  72%|▋| 100/138 [00:00<00:00, 162.33it/s, loss=4.17, v_num=1, val_loss=4.300,\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                              | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  87%|▊| 120/138 [00:00<00:00, 164.77it/s, loss=4.17, v_num=1, val_loss=4.300,\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████████▍      | 20/28 [00:00<00:00, 246.76it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 138/138 [00:00<00:00, 175.23it/s, loss=4.13, v_num=1, val_loss=4.150,\u001b[A\n",
      "Epoch 2:  72%|▋| 100/138 [00:00<00:00, 167.83it/s, loss=4.16, v_num=1, val_loss=4.150,\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                              | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  87%|▊| 120/138 [00:00<00:00, 165.11it/s, loss=4.16, v_num=1, val_loss=4.150,\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████████▍      | 20/28 [00:00<00:00, 172.34it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 138/138 [00:00<00:00, 168.96it/s, loss=4.12, v_num=1, val_loss=4.140,\u001b[A\n",
      "Epoch 3:  72%|▋| 100/138 [00:00<00:00, 203.03it/s, loss=4.15, v_num=1, val_loss=4.140,\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                              | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  87%|▊| 120/138 [00:00<00:00, 204.12it/s, loss=4.15, v_num=1, val_loss=4.140,\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████████▍      | 20/28 [00:00<00:00, 233.49it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 138/138 [00:00<00:00, 203.42it/s, loss=4.11, v_num=1, val_loss=4.140,\u001b[A\n",
      "Epoch 4:  72%|▋| 100/138 [00:00<00:00, 194.54it/s, loss=4.14, v_num=1, val_loss=4.140,\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                              | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  87%|▊| 120/138 [00:00<00:00, 191.35it/s, loss=4.14, v_num=1, val_loss=4.140,\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████████▍      | 20/28 [00:00<00:00, 234.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "system, trainer = train(\n",
    "    SigmoidNet,\n",
    "    OmegaConf.to_container(config),\n",
    "    experiment_dir=expt_dir,\n",
    "    checkpoint_name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b4d3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearEmbedder(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=19, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.05)\n",
      "    (2): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.05)\n",
      "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.05)\n",
      "    (6): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/johnzhou/research/decision-making/experiments/linear2D/model-v13.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpt_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/linear2D/model-v13.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m system \u001b[38;5;241m=\u001b[39m SigmoidNet(config)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_fname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     65\u001b[0m ):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m--> 184\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     extension \u001b[38;5;241m=\u001b[39m hparams_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/utilities/cloud_io.py:46\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\u001b[38;5;28mstr\u001b[39m(path_or_url), map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[1;32m     45\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/anaconda3/envs/ssm/lib/python3.10/site-packages/fsspec/spec.py:1034\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1034\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/anaconda3/envs/ssm/lib/python3.10/site-packages/fsspec/implementations/local.py:162\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ssm/lib/python3.10/site-packages/fsspec/implementations/local.py:260\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ssm/lib/python3.10/site-packages/fsspec/implementations/local.py:265\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 265\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    267\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/johnzhou/research/decision-making/experiments/linear2D/model-v13.ckpt'"
     ]
    }
   ],
   "source": [
    "X_fname = f\"{data_dir}/processed/{expt_name}/synth_feats.npy\"\n",
    "model_fname = f\"{expt_dir}/linear2D/model-v13.ckpt\"\n",
    "system = SigmoidNet(config)\n",
    "\n",
    "model = system.load_from_checkpoint(model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94ecc2",
   "metadata": {},
   "source": [
    "0.9 prew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_mse = torch.squeeze(model(torch.unsqueeze(torch.from_numpy(np.load(X_fname)).float(), 1))).detach().numpy()\n",
    "print(X_embedded_mse.shape)\n",
    "\n",
    "plt.figure()\n",
    "mse_boundary = 3995\n",
    "\n",
    "mf = plt.scatter(X_embedded_mse[:mse_boundary, 0], X_embedded_mse[:mse_boundary, 1], color='blue', s=20)\n",
    "mb = plt.scatter(X_embedded_mse[mse_boundary:, 0], X_embedded_mse[mse_boundary:, 1], color='red', s=10)\n",
    "\n",
    "plt.legend((mf, mb), ('Synth MF', 'Synth MB'), loc='upper right')\n",
    "\n",
    "border = -0.027\n",
    "plt.hlines(border, -.55, -.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529101cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"% of MF that are over:\", np.sum(X_embedded_mse[:mse_boundary, 1] > border) / X_embedded_mse[:mse_boundary, 1].size)\n",
    "print(\"% of MB that are under:\", np.sum(X_embedded_mse[mse_boundary:, 1] < border) / X_embedded_mse[mse_boundary:, 1].size)\n",
    "\n",
    "print(\"% of over that are MF:\",np.sum(X_embedded_mse[:mse_boundary, 1] > border) / np.sum(X_embedded_mse[:, 1] > border))\n",
    "print(\"% of under that are MB:\",np.sum(X_embedded_mse[mse_boundary:, 1] < border) / np.sum(X_embedded_mse[:, 1] < border))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47c3fc",
   "metadata": {},
   "source": [
    "1.0 prew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba62c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_mse = torch.squeeze(model(torch.unsqueeze(torch.from_numpy(np.load(X_fname)).float(), 1))).detach().numpy()\n",
    "print(X_embedded_mse.shape)\n",
    "\n",
    "plt.figure()\n",
    "mse_boundary = 42171\n",
    "\n",
    "# X_embedded_mse = normalize_features(X_embedded_mse)\n",
    "\n",
    "mf = plt.scatter(X_embedded_mse[:mse_boundary, 0], X_embedded_mse[:mse_boundary, 1], color='blue', s=20)\n",
    "mb = plt.scatter(X_embedded_mse[mse_boundary:, 0], X_embedded_mse[mse_boundary:, 1], color='red', s=10)\n",
    "# real = plt.scatter(X_embedded_mse[mse_boundary1:, 0], X_embedded_mse[mse_boundary1:, 1], color='yellow', s=5)\n",
    "\n",
    "borders = [-0.585, -0.57, -0.555, -0.51, -0.45, -0.35, -0.277]\n",
    "plt.legend((mf, mb), ('Synth MF', 'Synth MB'), loc='upper right')\n",
    "plt.vlines(borders, -0.6, 0, color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5242ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"% of MF that are left:\", np.sum(X_embedded_mse[:mse_boundary, 0] < border) / X_embedded_mse[:mse_boundary, 0].size)\n",
    "print(\"% of MB that are right:\", np.sum(X_embedded_mse[mse_boundary:, 0] > border) / X_embedded_mse[mse_boundary:, 0].size)\n",
    "\n",
    "print(\"% of left that are MF:\",np.sum(X_embedded_mse[:mse_boundary, 0] < border) / np.sum(X_embedded_mse[:, 0] < border))\n",
    "print(\"% of right that are MB:\",np.sum(X_embedded_mse[mse_boundary:, 0] > border) / np.sum(X_embedded_mse[:, 0] > border))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "mse_boundary = 42171\n",
    "\n",
    "mf = plt.scatter(X_embedded_mse[:mse_boundary, 0], X_embedded_mse[:mse_boundary, 1], color='blue', s=15)\n",
    "mb = plt.scatter(X_embedded_mse[mse_boundary:, 0], X_embedded_mse[mse_boundary:, 1], color='red', s=10)\n",
    "# real = plt.scatter(X_embedded_mse[mse_boundary1:, 0], X_embedded_mse[mse_boundary1:, 1], color='yellow', s=5)\n",
    "\n",
    "plt.legend((mf, mb), ('Synth MF', 'Synth MB'), loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
