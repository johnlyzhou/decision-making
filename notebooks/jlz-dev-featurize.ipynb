{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adeb008",
   "metadata": {},
   "source": [
    "# Featurize processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dc8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"/Users/johnzhou/research/decision-making\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7144e9",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c977cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b548b8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "\n",
    "from src.data.experiment_data import ExperimentData\n",
    "from src.features.build_features import normalize_features, remove_invalid_fits\n",
    "from src.models.sigmoidnet import SigmoidNet\n",
    "from src.models.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2939be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24945\n",
      "(49945, 1, 3)\n",
      "(49945, 1)\n",
      "(49945, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "expt_name = \"new_run\"\n",
    "bigboy = ExperimentData(expt_name, repo_path)\n",
    "# print(bigboy.sigmoid_parameters.shape, bigboy.foraging_efficiency.shape, bigboy.choice_blocks.shape)\n",
    "valid_idxs = bigboy.get_valid_idxs(boundary=50000)\n",
    "a = bigboy.build_modeling_feats(include_feff=False, include_block=False, idxs=valid_idxs)\n",
    "b = bigboy.build_modeling_labels(idxs=valid_idxs)\n",
    "\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976b27d",
   "metadata": {},
   "source": [
    "Sigmoid fitting with MSE loss seems to be empirically more sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03c9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.create({\n",
    "    \"name\": expt_name,\n",
    "    \"random_seed\": 4995,\n",
    "    \"model\": {\n",
    "        \"in_features\": 3,\n",
    "        \"linear_layers\": [32, 8, 4],\n",
    "        \"use_batch_norm\": False\n",
    "    },\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"data\": {\n",
    "        \"feature_path\": f\"{bigboy.data_path}/modeling_features.npy\",\n",
    "        \"label_path\": f\"{bigboy.data_path}/modeling_labels.npy\",\n",
    "        \"train_proportion\": 0.8,\n",
    "        \"train_batch_size\": 128,\n",
    "        \"val_batch_size\": 128\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"gpus\": 0,\n",
    "        \"max_epochs\": 1000\n",
    "    },\n",
    "\n",
    "})\n",
    "\n",
    "OmegaConf.save(config=config, f=f\"{repo_path}/configs/model_configs/sigmoidnet_train.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad76c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d4411880afbb5f49\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d4411880afbb5f49\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=$bigboy.data_path/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a327be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearEmbedder(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.05)\n",
      "    (2): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.05)\n",
      "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.05)\n",
      "    (6): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /Users/johnzhou/research/decision-making/data/processed/new_run/new_run/lightning_logs\n",
      "\n",
      "  | Name  | Type           | Params\n",
      "-----------------------------------------\n",
      "0 | loss  | SupConLoss     | 0     \n",
      "1 | model | LinearEmbedder | 438   \n",
      "-----------------------------------------\n",
      "438       Trainable params\n",
      "0         Non-trainable params\n",
      "438       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|                                 | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnzhou/anaconda3/envs/ssm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  77%|████████████████     | 300/392 [00:01<00:00, 234.44it/s, loss=4.84, v_num=0]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  82%|█████████████████▏   | 320/392 [00:01<00:00, 233.12it/s, loss=4.84, v_num=0]\u001b[A\n",
      "Epoch 0:  87%|██████████████████▏  | 340/392 [00:01<00:00, 237.92it/s, loss=4.84, v_num=0]\u001b[A\n",
      "Epoch 0:  92%|███████████████████▎ | 360/392 [00:01<00:00, 241.01it/s, loss=4.84, v_num=0]\u001b[A\n",
      "Epoch 0:  97%|████████████████████▎| 380/392 [00:01<00:00, 244.92it/s, loss=4.84, v_num=0]\u001b[A\n",
      "Epoch 0: 100%|█████| 392/392 [00:01<00:00, 244.13it/s, loss=4.75, v_num=0, val_loss=4.840]\u001b[A\n",
      "Epoch 1:  77%|▊| 300/392 [00:01<00:00, 221.86it/s, loss=4.84, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  82%|▊| 320/392 [00:01<00:00, 218.06it/s, loss=4.84, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 1:  87%|▊| 340/392 [00:01<00:00, 222.87it/s, loss=4.84, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 1:  92%|▉| 360/392 [00:01<00:00, 224.89it/s, loss=4.84, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 1:  97%|▉| 380/392 [00:01<00:00, 228.23it/s, loss=4.84, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 1: 100%|█| 392/392 [00:01<00:00, 227.85it/s, loss=4.75, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 2:  77%|▊| 300/392 [00:01<00:00, 217.46it/s, loss=4.81, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  82%|▊| 320/392 [00:01<00:00, 213.98it/s, loss=4.81, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 2:  87%|▊| 340/392 [00:01<00:00, 217.24it/s, loss=4.81, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 2:  92%|▉| 360/392 [00:01<00:00, 221.93it/s, loss=4.81, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 2:  97%|▉| 380/392 [00:01<00:00, 224.30it/s, loss=4.81, v_num=0, val_loss=4.840, tra\u001b[A\n",
      "Epoch 2: 100%|█| 392/392 [00:01<00:00, 225.46it/s, loss=4.71, v_num=0, val_loss=4.800, tra\u001b[A\n",
      "Epoch 3:  77%|▊| 300/392 [00:01<00:00, 241.20it/s, loss=4.74, v_num=0, val_loss=4.800, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  82%|▊| 320/392 [00:01<00:00, 240.34it/s, loss=4.74, v_num=0, val_loss=4.800, tra\u001b[A\n",
      "Epoch 3:  87%|▊| 340/392 [00:01<00:00, 241.65it/s, loss=4.74, v_num=0, val_loss=4.800, tra\u001b[A\n",
      "Epoch 3:  92%|▉| 360/392 [00:01<00:00, 244.60it/s, loss=4.74, v_num=0, val_loss=4.800, tra\u001b[A\n",
      "Epoch 3:  97%|▉| 380/392 [00:01<00:00, 248.71it/s, loss=4.74, v_num=0, val_loss=4.800, tra\u001b[A\n",
      "Epoch 3: 100%|█| 392/392 [00:01<00:00, 250.72it/s, loss=4.65, v_num=0, val_loss=4.740, tra\u001b[A\n",
      "Epoch 4:  77%|▊| 300/392 [00:01<00:00, 233.76it/s, loss=4.72, v_num=0, val_loss=4.740, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  82%|▊| 320/392 [00:01<00:00, 229.47it/s, loss=4.72, v_num=0, val_loss=4.740, tra\u001b[A\n",
      "Epoch 4:  87%|▊| 340/392 [00:01<00:00, 233.98it/s, loss=4.72, v_num=0, val_loss=4.740, tra\u001b[A\n",
      "Epoch 4:  92%|▉| 360/392 [00:01<00:00, 237.44it/s, loss=4.72, v_num=0, val_loss=4.740, tra\u001b[A\n",
      "Epoch 4:  97%|▉| 380/392 [00:01<00:00, 240.83it/s, loss=4.72, v_num=0, val_loss=4.740, tra\u001b[A\n",
      "Epoch 4: 100%|█| 392/392 [00:01<00:00, 241.63it/s, loss=4.64, v_num=0, val_loss=4.720, tra\u001b[A\n",
      "Epoch 5:  77%|▊| 300/392 [00:01<00:00, 232.35it/s, loss=4.7, v_num=0, val_loss=4.720, trai\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  82%|▊| 320/392 [00:01<00:00, 229.18it/s, loss=4.7, v_num=0, val_loss=4.720, trai\u001b[A\n",
      "Epoch 5:  87%|▊| 340/392 [00:01<00:00, 231.81it/s, loss=4.7, v_num=0, val_loss=4.720, trai\u001b[A\n",
      "Epoch 5:  92%|▉| 360/392 [00:01<00:00, 235.40it/s, loss=4.7, v_num=0, val_loss=4.720, trai\u001b[A\n",
      "Epoch 5:  97%|▉| 380/392 [00:01<00:00, 238.94it/s, loss=4.7, v_num=0, val_loss=4.720, trai\u001b[A\n",
      "Epoch 5: 100%|█| 392/392 [00:01<00:00, 240.38it/s, loss=4.62, v_num=0, val_loss=4.700, tra\u001b[A\n",
      "Epoch 6:  77%|▊| 300/392 [00:01<00:00, 232.21it/s, loss=4.67, v_num=0, val_loss=4.700, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  82%|▊| 320/392 [00:01<00:00, 230.07it/s, loss=4.67, v_num=0, val_loss=4.700, tra\u001b[A\n",
      "Epoch 6:  87%|▊| 340/392 [00:01<00:00, 232.06it/s, loss=4.67, v_num=0, val_loss=4.700, tra\u001b[A\n",
      "Epoch 6:  92%|▉| 360/392 [00:01<00:00, 232.52it/s, loss=4.67, v_num=0, val_loss=4.700, tra\u001b[A\n",
      "Epoch 6:  97%|▉| 380/392 [00:01<00:00, 233.66it/s, loss=4.67, v_num=0, val_loss=4.700, tra\u001b[A\n",
      "Epoch 6: 100%|█| 392/392 [00:01<00:00, 234.59it/s, loss=4.59, v_num=0, val_loss=4.670, tra\u001b[A\n",
      "Epoch 7:  77%|▊| 300/392 [00:01<00:00, 229.08it/s, loss=4.64, v_num=0, val_loss=4.670, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  82%|▊| 320/392 [00:01<00:00, 227.66it/s, loss=4.64, v_num=0, val_loss=4.670, tra\u001b[A\n",
      "Epoch 7:  87%|▊| 340/392 [00:01<00:00, 227.98it/s, loss=4.64, v_num=0, val_loss=4.670, tra\u001b[A\n",
      "Epoch 7:  92%|▉| 360/392 [00:01<00:00, 231.85it/s, loss=4.64, v_num=0, val_loss=4.670, tra\u001b[A\n",
      "Epoch 7:  97%|▉| 380/392 [00:01<00:00, 235.76it/s, loss=4.64, v_num=0, val_loss=4.670, tra\u001b[A\n",
      "Epoch 7: 100%|█| 392/392 [00:01<00:00, 237.37it/s, loss=4.56, v_num=0, val_loss=4.640, tra\u001b[A\n",
      "Epoch 8:  77%|▊| 300/392 [00:01<00:00, 229.06it/s, loss=4.6, v_num=0, val_loss=4.640, trai\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  82%|▊| 320/392 [00:01<00:00, 226.39it/s, loss=4.6, v_num=0, val_loss=4.640, trai\u001b[A\n",
      "Epoch 8:  87%|▊| 340/392 [00:01<00:00, 231.24it/s, loss=4.6, v_num=0, val_loss=4.640, trai\u001b[A\n",
      "Epoch 8:  92%|▉| 360/392 [00:01<00:00, 236.00it/s, loss=4.6, v_num=0, val_loss=4.640, trai\u001b[A\n",
      "Epoch 8:  97%|▉| 380/392 [00:01<00:00, 240.39it/s, loss=4.6, v_num=0, val_loss=4.640, trai\u001b[A\n",
      "Epoch 8: 100%|█| 392/392 [00:01<00:00, 241.80it/s, loss=4.53, v_num=0, val_loss=4.610, tra\u001b[A\n",
      "Epoch 9:  77%|▊| 300/392 [00:01<00:00, 226.36it/s, loss=4.57, v_num=0, val_loss=4.610, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  82%|▊| 320/392 [00:01<00:00, 223.75it/s, loss=4.57, v_num=0, val_loss=4.610, tra\u001b[A\n",
      "Epoch 9:  87%|▊| 340/392 [00:01<00:00, 229.11it/s, loss=4.57, v_num=0, val_loss=4.610, tra\u001b[A\n",
      "Epoch 9:  92%|▉| 360/392 [00:01<00:00, 233.81it/s, loss=4.57, v_num=0, val_loss=4.610, tra\u001b[A\n",
      "Epoch 9:  97%|▉| 380/392 [00:01<00:00, 238.09it/s, loss=4.57, v_num=0, val_loss=4.610, tra\u001b[A\n",
      "Epoch 9: 100%|█| 392/392 [00:01<00:00, 240.09it/s, loss=4.51, v_num=0, val_loss=4.580, tra\u001b[A\n",
      "Epoch 10:  77%|▊| 300/392 [00:01<00:00, 225.73it/s, loss=4.55, v_num=0, val_loss=4.580, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  82%|▊| 320/392 [00:01<00:00, 224.64it/s, loss=4.55, v_num=0, val_loss=4.580, tr\u001b[A\n",
      "Epoch 10:  87%|▊| 340/392 [00:01<00:00, 229.12it/s, loss=4.55, v_num=0, val_loss=4.580, tr\u001b[A\n",
      "Epoch 10:  92%|▉| 360/392 [00:01<00:00, 234.07it/s, loss=4.55, v_num=0, val_loss=4.580, tr\u001b[A\n",
      "Epoch 10:  97%|▉| 380/392 [00:01<00:00, 237.97it/s, loss=4.55, v_num=0, val_loss=4.580, tr\u001b[A\n",
      "Epoch 10: 100%|█| 392/392 [00:01<00:00, 236.23it/s, loss=4.48, v_num=0, val_loss=4.560, tr\u001b[A\n",
      "Epoch 11:  77%|▊| 300/392 [00:01<00:00, 225.51it/s, loss=4.54, v_num=0, val_loss=4.560, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  82%|▊| 320/392 [00:01<00:00, 224.61it/s, loss=4.54, v_num=0, val_loss=4.560, tr\u001b[A\n",
      "Epoch 11:  87%|▊| 340/392 [00:01<00:00, 229.64it/s, loss=4.54, v_num=0, val_loss=4.560, tr\u001b[A\n",
      "Epoch 11:  92%|▉| 360/392 [00:01<00:00, 234.78it/s, loss=4.54, v_num=0, val_loss=4.560, tr\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  97%|▉| 380/392 [00:01<00:00, 239.27it/s, loss=4.54, v_num=0, val_loss=4.560, tr\u001b[A\n",
      "Epoch 11: 100%|█| 392/392 [00:01<00:00, 240.93it/s, loss=4.47, v_num=0, val_loss=4.540, tr\u001b[A\n",
      "Epoch 12:  77%|▊| 300/392 [00:01<00:00, 228.48it/s, loss=4.53, v_num=0, val_loss=4.540, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  82%|▊| 320/392 [00:01<00:00, 227.17it/s, loss=4.53, v_num=0, val_loss=4.540, tr\u001b[A\n",
      "Epoch 12:  87%|▊| 340/392 [00:01<00:00, 231.88it/s, loss=4.53, v_num=0, val_loss=4.540, tr\u001b[A\n",
      "Epoch 12:  92%|▉| 360/392 [00:01<00:00, 236.34it/s, loss=4.53, v_num=0, val_loss=4.540, tr\u001b[A\n",
      "Epoch 12:  97%|▉| 380/392 [00:01<00:00, 240.85it/s, loss=4.53, v_num=0, val_loss=4.540, tr\u001b[A\n",
      "Epoch 12: 100%|█| 392/392 [00:01<00:00, 243.19it/s, loss=4.46, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 13:  77%|▊| 300/392 [00:01<00:00, 225.57it/s, loss=4.52, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  82%|▊| 320/392 [00:01<00:00, 224.50it/s, loss=4.52, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 13:  87%|▊| 340/392 [00:01<00:00, 229.59it/s, loss=4.52, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 13:  92%|▉| 360/392 [00:01<00:00, 234.72it/s, loss=4.52, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 13:  97%|▉| 380/392 [00:01<00:00, 239.57it/s, loss=4.52, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 13: 100%|█| 392/392 [00:01<00:00, 241.96it/s, loss=4.45, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 14:  77%|▊| 300/392 [00:01<00:00, 226.17it/s, loss=4.51, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  82%|▊| 320/392 [00:01<00:00, 223.64it/s, loss=4.51, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 14:  87%|▊| 340/392 [00:01<00:00, 228.23it/s, loss=4.51, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 14:  92%|▉| 360/392 [00:01<00:00, 232.69it/s, loss=4.51, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 14:  97%|▉| 380/392 [00:01<00:00, 236.90it/s, loss=4.51, v_num=0, val_loss=4.530, tr\u001b[A\n",
      "Epoch 14: 100%|█| 392/392 [00:01<00:00, 239.41it/s, loss=4.45, v_num=0, val_loss=4.520, tr\u001b[A\n",
      "Epoch 15:  77%|▊| 300/392 [00:01<00:00, 227.21it/s, loss=4.5, v_num=0, val_loss=4.520, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  82%|▊| 320/392 [00:01<00:00, 225.97it/s, loss=4.5, v_num=0, val_loss=4.520, tra\u001b[A\n",
      "Epoch 15:  87%|▊| 340/392 [00:01<00:00, 231.46it/s, loss=4.5, v_num=0, val_loss=4.520, tra\u001b[A\n",
      "Epoch 15:  92%|▉| 360/392 [00:01<00:00, 236.06it/s, loss=4.5, v_num=0, val_loss=4.520, tra\u001b[A\n",
      "Epoch 15:  97%|▉| 380/392 [00:01<00:00, 240.42it/s, loss=4.5, v_num=0, val_loss=4.520, tra\u001b[A\n",
      "Epoch 15: 100%|█| 392/392 [00:01<00:00, 242.20it/s, loss=4.44, v_num=0, val_loss=4.510, tr\u001b[A\n",
      "Epoch 16:  77%|▊| 300/392 [00:01<00:00, 266.98it/s, loss=4.5, v_num=0, val_loss=4.510, tra\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  82%|▊| 320/392 [00:01<00:00, 265.52it/s, loss=4.5, v_num=0, val_loss=4.510, tra\u001b[A\n",
      "Epoch 16:  87%|▊| 340/392 [00:01<00:00, 272.28it/s, loss=4.5, v_num=0, val_loss=4.510, tra\u001b[A\n",
      "Epoch 16:  92%|▉| 360/392 [00:01<00:00, 279.01it/s, loss=4.5, v_num=0, val_loss=4.510, tra\u001b[A\n",
      "Epoch 16:  97%|▉| 380/392 [00:01<00:00, 285.58it/s, loss=4.5, v_num=0, val_loss=4.510, tra\u001b[A\n",
      "Epoch 16: 100%|█| 392/392 [00:01<00:00, 288.57it/s, loss=4.44, v_num=0, val_loss=4.510, tr\u001b[A\n",
      "Epoch 17:  77%|▊| 300/392 [00:01<00:00, 271.92it/s, loss=4.49, v_num=0, val_loss=4.510, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  82%|▊| 320/392 [00:01<00:00, 266.67it/s, loss=4.49, v_num=0, val_loss=4.510, tr\u001b[A\n",
      "Epoch 17:  87%|▊| 340/392 [00:01<00:00, 271.27it/s, loss=4.49, v_num=0, val_loss=4.510, tr\u001b[A\n",
      "Epoch 17:  92%|▉| 360/392 [00:01<00:00, 275.71it/s, loss=4.49, v_num=0, val_loss=4.510, tr\u001b[A\n",
      "Epoch 17:  97%|▉| 380/392 [00:01<00:00, 277.82it/s, loss=4.49, v_num=0, val_loss=4.510, tr\u001b[A\n",
      "Epoch 17: 100%|█| 392/392 [00:01<00:00, 276.80it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 18:  77%|▊| 300/392 [00:01<00:00, 227.67it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  82%|▊| 320/392 [00:01<00:00, 226.64it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 18:  87%|▊| 340/392 [00:01<00:00, 232.02it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 18:  92%|▉| 360/392 [00:01<00:00, 237.00it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 18:  97%|▉| 380/392 [00:01<00:00, 241.92it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 18: 100%|█| 392/392 [00:01<00:00, 243.86it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 19:  77%|▊| 300/392 [00:01<00:00, 226.27it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  82%|▊| 320/392 [00:01<00:00, 225.45it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 19:  87%|▊| 340/392 [00:01<00:00, 231.07it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 19:  92%|▉| 360/392 [00:01<00:00, 236.58it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 19:  97%|▉| 380/392 [00:01<00:00, 241.50it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 19: 100%|█| 392/392 [00:01<00:00, 243.53it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 20:  77%|▊| 300/392 [00:01<00:00, 227.05it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  82%|▊| 320/392 [00:01<00:00, 225.90it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 20:  87%|▊| 340/392 [00:01<00:00, 231.07it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 20:  92%|▉| 360/392 [00:01<00:00, 235.98it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 20:  97%|▉| 380/392 [00:01<00:00, 240.62it/s, loss=4.49, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 20: 100%|█| 392/392 [00:01<00:00, 242.65it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 21:  77%|▊| 300/392 [00:01<00:00, 227.36it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  82%|▊| 320/392 [00:01<00:00, 226.08it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 21:  87%|▊| 340/392 [00:01<00:00, 227.77it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 21:  92%|▉| 360/392 [00:01<00:00, 232.80it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 21:  97%|▉| 380/392 [00:01<00:00, 237.48it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 21: 100%|█| 392/392 [00:01<00:00, 239.74it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 22:  77%|▊| 300/392 [00:01<00:00, 224.67it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  82%|▊| 320/392 [00:01<00:00, 223.51it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 22:  87%|▊| 340/392 [00:01<00:00, 228.99it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 22:  92%|▉| 360/392 [00:01<00:00, 233.14it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 22:  97%|▉| 380/392 [00:01<00:00, 237.95it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 22: 100%|█| 392/392 [00:01<00:00, 239.92it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 23:  77%|▊| 300/392 [00:01<00:00, 225.44it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  82%|▊| 320/392 [00:01<00:00, 224.02it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  87%|▊| 340/392 [00:01<00:00, 229.24it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 23:  92%|▉| 360/392 [00:01<00:00, 234.88it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 23:  97%|▉| 380/392 [00:01<00:00, 239.73it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 23: 100%|█| 392/392 [00:01<00:00, 242.07it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 24:  77%|▊| 300/392 [00:01<00:00, 227.51it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  82%|▊| 320/392 [00:01<00:00, 226.37it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 24:  87%|▊| 340/392 [00:01<00:00, 231.37it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 24:  92%|▉| 360/392 [00:01<00:00, 236.60it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 24:  97%|▉| 380/392 [00:01<00:00, 241.31it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 24: 100%|█| 392/392 [00:01<00:00, 243.36it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 25:  77%|▊| 300/392 [00:01<00:00, 225.94it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  82%|▊| 320/392 [00:01<00:00, 224.87it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 25:  87%|▊| 340/392 [00:01<00:00, 230.53it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 25:  92%|▉| 360/392 [00:01<00:00, 235.84it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 25:  97%|▉| 380/392 [00:01<00:00, 240.45it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 25: 100%|█| 392/392 [00:01<00:00, 242.41it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 26:  77%|▊| 300/392 [00:01<00:00, 226.56it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  82%|▊| 320/392 [00:01<00:00, 226.03it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 26:  87%|▊| 340/392 [00:01<00:00, 230.89it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 26:  92%|▉| 360/392 [00:01<00:00, 236.24it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 26:  97%|▉| 380/392 [00:01<00:00, 241.06it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 26: 100%|█| 392/392 [00:01<00:00, 241.95it/s, loss=4.43, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 27:  77%|▊| 300/392 [00:01<00:00, 224.90it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  82%|▊| 320/392 [00:01<00:00, 223.77it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 27:  87%|▊| 340/392 [00:01<00:00, 229.11it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 27:  92%|▉| 360/392 [00:01<00:00, 234.34it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 27:  97%|▉| 380/392 [00:01<00:00, 239.11it/s, loss=4.48, v_num=0, val_loss=4.500, tr\u001b[A\n",
      "Epoch 27: 100%|█| 392/392 [00:01<00:00, 241.15it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 28:  77%|▊| 300/392 [00:01<00:00, 224.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  82%|▊| 320/392 [00:01<00:00, 223.79it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 28:  87%|▊| 340/392 [00:01<00:00, 228.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 28:  92%|▉| 360/392 [00:01<00:00, 233.79it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 28:  97%|▉| 380/392 [00:01<00:00, 238.64it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 28: 100%|█| 392/392 [00:01<00:00, 240.84it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 29:  77%|▊| 300/392 [00:01<00:00, 225.25it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  82%|▊| 320/392 [00:01<00:00, 224.45it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 29:  87%|▊| 340/392 [00:01<00:00, 229.32it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 29:  92%|▉| 360/392 [00:01<00:00, 234.47it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 29:  97%|▉| 380/392 [00:01<00:00, 239.43it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 29: 100%|█| 392/392 [00:01<00:00, 241.44it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 30:  77%|▊| 300/392 [00:01<00:00, 224.43it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  82%|▊| 320/392 [00:01<00:00, 223.65it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 30:  87%|▊| 340/392 [00:01<00:00, 228.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 30:  92%|▉| 360/392 [00:01<00:00, 233.75it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 30:  97%|▉| 380/392 [00:01<00:00, 238.27it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 30: 100%|█| 392/392 [00:01<00:00, 240.41it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 31:  77%|▊| 300/392 [00:01<00:00, 223.96it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  82%|▊| 320/392 [00:01<00:00, 221.83it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 31:  87%|▊| 340/392 [00:01<00:00, 227.01it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 31:  92%|▉| 360/392 [00:01<00:00, 232.37it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 31:  97%|▉| 380/392 [00:01<00:00, 236.53it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 31: 100%|█| 392/392 [00:01<00:00, 238.84it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 32:  77%|▊| 300/392 [00:01<00:00, 227.10it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  82%|▊| 320/392 [00:01<00:00, 225.82it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 32:  87%|▊| 340/392 [00:01<00:00, 231.13it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 32:  92%|▉| 360/392 [00:01<00:00, 236.17it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 32:  97%|▉| 380/392 [00:01<00:00, 240.97it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 32: 100%|█| 392/392 [00:01<00:00, 242.96it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 33:  77%|▊| 300/392 [00:01<00:00, 226.31it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  82%|▊| 320/392 [00:01<00:00, 224.77it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 33:  87%|▊| 340/392 [00:01<00:00, 229.83it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 33:  92%|▉| 360/392 [00:01<00:00, 234.16it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 33:  97%|▉| 380/392 [00:01<00:00, 238.80it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 33: 100%|█| 392/392 [00:01<00:00, 240.81it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 34:  77%|▊| 300/392 [00:01<00:00, 224.27it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  82%|▊| 320/392 [00:01<00:00, 222.73it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 34:  87%|▊| 340/392 [00:01<00:00, 226.60it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 34:  92%|▉| 360/392 [00:01<00:00, 231.28it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 34:  97%|▉| 380/392 [00:01<00:00, 235.87it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 34: 100%|█| 392/392 [00:01<00:00, 237.34it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 35:  77%|▊| 300/392 [00:01<00:00, 220.98it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  82%|▊| 320/392 [00:01<00:00, 219.85it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 35:  87%|▊| 340/392 [00:01<00:00, 225.02it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 35:  92%|▉| 360/392 [00:01<00:00, 230.11it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 35:  97%|▉| 380/392 [00:01<00:00, 234.64it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 35: 100%|█| 392/392 [00:01<00:00, 235.99it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 36:  77%|▊| 300/392 [00:01<00:00, 224.14it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  82%|▊| 320/392 [00:01<00:00, 223.02it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 36:  87%|▊| 340/392 [00:01<00:00, 228.92it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 36:  92%|▉| 360/392 [00:01<00:00, 232.39it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 36:  97%|▉| 380/392 [00:01<00:00, 237.35it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 36: 100%|█| 392/392 [00:01<00:00, 239.30it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 37:  77%|▊| 300/392 [00:01<00:00, 225.71it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  82%|▊| 320/392 [00:01<00:00, 224.73it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 37:  87%|▊| 340/392 [00:01<00:00, 230.00it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 37:  92%|▉| 360/392 [00:01<00:00, 234.52it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 37:  97%|▉| 380/392 [00:01<00:00, 238.54it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 37: 100%|█| 392/392 [00:01<00:00, 240.81it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 38:  77%|▊| 300/392 [00:01<00:00, 226.80it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  82%|▊| 320/392 [00:01<00:00, 225.67it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 38:  87%|▊| 340/392 [00:01<00:00, 230.84it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 38:  92%|▉| 360/392 [00:01<00:00, 235.80it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 38:  97%|▉| 380/392 [00:01<00:00, 240.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 38: 100%|█| 392/392 [00:01<00:00, 242.02it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 39:  77%|▊| 300/392 [00:01<00:00, 224.72it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  82%|▊| 320/392 [00:01<00:00, 222.91it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 39:  87%|▊| 340/392 [00:01<00:00, 228.45it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 39:  92%|▉| 360/392 [00:01<00:00, 233.55it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 39:  97%|▉| 380/392 [00:01<00:00, 236.97it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 39: 100%|█| 392/392 [00:01<00:00, 239.32it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 40:  77%|▊| 300/392 [00:01<00:00, 224.20it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  82%|▊| 320/392 [00:01<00:00, 222.20it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 40:  87%|▊| 340/392 [00:01<00:00, 227.87it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 40:  92%|▉| 360/392 [00:01<00:00, 233.24it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 40:  97%|▉| 380/392 [00:01<00:00, 237.93it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 40: 100%|█| 392/392 [00:01<00:00, 239.01it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 41:  77%|▊| 300/392 [00:01<00:00, 221.70it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  82%|▊| 320/392 [00:01<00:00, 220.36it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 41:  87%|▊| 340/392 [00:01<00:00, 226.14it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 41:  92%|▉| 360/392 [00:01<00:00, 231.34it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 41:  97%|▉| 380/392 [00:01<00:00, 231.44it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 41: 100%|█| 392/392 [00:01<00:00, 232.81it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 42:  77%|▊| 300/392 [00:01<00:00, 220.49it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  82%|▊| 320/392 [00:01<00:00, 219.82it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 42:  87%|▊| 340/392 [00:01<00:00, 225.37it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 42:  92%|▉| 360/392 [00:01<00:00, 230.17it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 42:  97%|▉| 380/392 [00:01<00:00, 234.59it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 42: 100%|█| 392/392 [00:01<00:00, 236.81it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 43:  77%|▊| 300/392 [00:01<00:00, 273.79it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  82%|▊| 320/392 [00:01<00:00, 274.22it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 43:  87%|▊| 340/392 [00:01<00:00, 281.41it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 43:  92%|▉| 360/392 [00:01<00:00, 288.14it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 43:  97%|▉| 380/392 [00:01<00:00, 294.45it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 43: 100%|█| 392/392 [00:01<00:00, 297.52it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 44:  77%|▊| 300/392 [00:01<00:00, 282.94it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  82%|▊| 320/392 [00:01<00:00, 281.01it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 44:  87%|▊| 340/392 [00:01<00:00, 288.88it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 44:  92%|▉| 360/392 [00:01<00:00, 295.75it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 44:  97%|▉| 380/392 [00:01<00:00, 301.08it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 44: 100%|█| 392/392 [00:01<00:00, 303.55it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 45:  77%|▊| 300/392 [00:01<00:00, 284.77it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  82%|▊| 320/392 [00:01<00:00, 284.21it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 45:  87%|▊| 340/392 [00:01<00:00, 290.60it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 45:  92%|▉| 360/392 [00:01<00:00, 297.11it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 45:  97%|▉| 380/392 [00:01<00:00, 302.71it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 45: 100%|█| 392/392 [00:01<00:00, 305.65it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 46:  77%|▊| 300/392 [00:01<00:00, 223.77it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  82%|▊| 320/392 [00:01<00:00, 223.11it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 46:  87%|▊| 340/392 [00:01<00:00, 228.22it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 46:  92%|▉| 360/392 [00:01<00:00, 233.01it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 46:  97%|▉| 380/392 [00:01<00:00, 236.87it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 46: 100%|█| 392/392 [00:01<00:00, 239.02it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:  77%|▊| 300/392 [00:01<00:00, 227.00it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  82%|▊| 320/392 [00:01<00:00, 226.48it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 47:  87%|▊| 340/392 [00:01<00:00, 232.20it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 47:  92%|▉| 360/392 [00:01<00:00, 237.10it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 47:  97%|▉| 380/392 [00:01<00:00, 241.91it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 47: 100%|█| 392/392 [00:01<00:00, 244.04it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 48:  77%|▊| 300/392 [00:01<00:00, 227.31it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  82%|▊| 320/392 [00:01<00:00, 225.60it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 48:  87%|▊| 340/392 [00:01<00:00, 231.02it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 48:  92%|▉| 360/392 [00:01<00:00, 236.00it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 48:  97%|▉| 380/392 [00:01<00:00, 240.25it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 48: 100%|█| 392/392 [00:01<00:00, 242.47it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 49:  77%|▊| 300/392 [00:01<00:00, 213.24it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  82%|▊| 320/392 [00:01<00:00, 213.26it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 49:  87%|▊| 340/392 [00:01<00:00, 218.60it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 49:  92%|▉| 360/392 [00:01<00:00, 223.77it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 49:  97%|▉| 380/392 [00:01<00:00, 228.39it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 49: 100%|█| 392/392 [00:01<00:00, 230.88it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 50:  77%|▊| 300/392 [00:01<00:00, 223.81it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 50:  82%|▊| 320/392 [00:01<00:00, 222.24it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 50:  87%|▊| 340/392 [00:01<00:00, 227.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 50:  92%|▉| 360/392 [00:01<00:00, 232.76it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 50:  97%|▉| 380/392 [00:01<00:00, 237.35it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 50: 100%|█| 392/392 [00:01<00:00, 238.93it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 51:  77%|▊| 300/392 [00:01<00:00, 223.84it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  82%|▊| 320/392 [00:01<00:00, 222.37it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 51:  87%|▊| 340/392 [00:01<00:00, 227.16it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 51:  92%|▉| 360/392 [00:01<00:00, 232.39it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 51:  97%|▉| 380/392 [00:01<00:00, 237.39it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 51: 100%|█| 392/392 [00:01<00:00, 239.46it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 52:  77%|▊| 300/392 [00:01<00:00, 220.59it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  82%|▊| 320/392 [00:01<00:00, 219.01it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 52:  87%|▊| 340/392 [00:01<00:00, 224.10it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 52:  92%|▉| 360/392 [00:01<00:00, 229.38it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 52:  97%|▉| 380/392 [00:01<00:00, 233.05it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 52: 100%|█| 392/392 [00:01<00:00, 233.93it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 53:  77%|▊| 300/392 [00:01<00:00, 220.20it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  82%|▊| 320/392 [00:01<00:00, 219.15it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 53:  87%|▊| 340/392 [00:01<00:00, 223.86it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 53:  92%|▉| 360/392 [00:01<00:00, 229.12it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 53:  97%|▉| 380/392 [00:01<00:00, 233.45it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 53: 100%|█| 392/392 [00:01<00:00, 235.22it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 54:  77%|▊| 300/392 [00:01<00:00, 222.56it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  82%|▊| 320/392 [00:01<00:00, 221.16it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 54:  87%|▊| 340/392 [00:01<00:00, 226.52it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 54:  92%|▉| 360/392 [00:01<00:00, 231.62it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 54:  97%|▉| 380/392 [00:01<00:00, 236.53it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 54: 100%|█| 392/392 [00:01<00:00, 237.45it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 55:  77%|▊| 300/392 [00:01<00:00, 223.62it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  82%|▊| 320/392 [00:01<00:00, 222.54it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 55:  87%|▊| 340/392 [00:01<00:00, 227.23it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 55:  92%|▉| 360/392 [00:01<00:00, 232.16it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 55:  97%|▉| 380/392 [00:01<00:00, 235.45it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 55: 100%|█| 392/392 [00:01<00:00, 237.66it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 56:  77%|▊| 300/392 [00:01<00:00, 224.76it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  82%|▊| 320/392 [00:01<00:00, 223.28it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 56:  87%|▊| 340/392 [00:01<00:00, 228.77it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 56:  92%|▉| 360/392 [00:01<00:00, 233.61it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 56:  97%|▉| 380/392 [00:01<00:00, 238.24it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 56: 100%|█| 392/392 [00:01<00:00, 239.84it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 57:  77%|▊| 300/392 [00:01<00:00, 224.59it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  82%|▊| 320/392 [00:01<00:00, 221.82it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 57:  87%|▊| 340/392 [00:01<00:00, 227.06it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 57:  92%|▉| 360/392 [00:01<00:00, 230.85it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 57:  97%|▉| 380/392 [00:01<00:00, 235.50it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 57: 100%|█| 392/392 [00:01<00:00, 237.91it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 58:  77%|▊| 300/392 [00:01<00:00, 225.95it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  82%|▊| 320/392 [00:01<00:00, 224.45it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 58:  87%|▊| 340/392 [00:01<00:00, 229.98it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 58:  92%|▉| 360/392 [00:01<00:00, 235.00it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58:  97%|▉| 380/392 [00:01<00:00, 239.37it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 58: 100%|█| 392/392 [00:01<00:00, 241.39it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 59:  77%|▊| 300/392 [00:01<00:00, 227.24it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  82%|▊| 320/392 [00:01<00:00, 226.06it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 59:  87%|▊| 340/392 [00:01<00:00, 231.56it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 59:  92%|▉| 360/392 [00:01<00:00, 236.53it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 59:  97%|▉| 380/392 [00:01<00:00, 240.97it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 59: 100%|█| 392/392 [00:01<00:00, 243.35it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 60:  77%|▊| 300/392 [00:01<00:00, 224.61it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  82%|▊| 320/392 [00:01<00:00, 223.48it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 60:  87%|▊| 340/392 [00:01<00:00, 228.42it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 60:  92%|▉| 360/392 [00:01<00:00, 233.00it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 60:  97%|▉| 380/392 [00:01<00:00, 237.36it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 60: 100%|█| 392/392 [00:01<00:00, 239.51it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 61:  77%|▊| 300/392 [00:01<00:00, 224.86it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  82%|▊| 320/392 [00:01<00:00, 223.30it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 61:  87%|▊| 340/392 [00:01<00:00, 228.59it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 61:  92%|▉| 360/392 [00:01<00:00, 233.55it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 61:  97%|▉| 380/392 [00:01<00:00, 238.15it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 61: 100%|█| 392/392 [00:01<00:00, 239.87it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 62:  77%|▊| 300/392 [00:01<00:00, 223.52it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62:  82%|▊| 320/392 [00:01<00:00, 222.64it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 62:  87%|▊| 340/392 [00:01<00:00, 227.29it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 62:  92%|▉| 360/392 [00:01<00:00, 231.23it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 62:  97%|▉| 380/392 [00:01<00:00, 232.68it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 62: 100%|█| 392/392 [00:01<00:00, 234.99it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 63:  77%|▊| 300/392 [00:01<00:00, 222.49it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63:  82%|▊| 320/392 [00:01<00:00, 222.63it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 63:  87%|▊| 340/392 [00:01<00:00, 227.82it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 63:  92%|▉| 360/392 [00:01<00:00, 230.06it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 63:  97%|▉| 380/392 [00:01<00:00, 224.64it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 63: 100%|█| 392/392 [00:01<00:00, 225.96it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 64:  77%|▊| 300/392 [00:01<00:00, 225.00it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  82%|▊| 320/392 [00:01<00:00, 223.91it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 64:  87%|▊| 340/392 [00:01<00:00, 229.13it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 64:  92%|▉| 360/392 [00:01<00:00, 233.94it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 64:  97%|▉| 380/392 [00:01<00:00, 237.60it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 64: 100%|█| 392/392 [00:01<00:00, 239.62it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 65:  77%|▊| 300/392 [00:01<00:00, 225.94it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  82%|▊| 320/392 [00:01<00:00, 224.94it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 65:  87%|▊| 340/392 [00:01<00:00, 230.41it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 65:  92%|▉| 360/392 [00:01<00:00, 235.60it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 65:  97%|▉| 380/392 [00:01<00:00, 240.45it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 65: 100%|█| 392/392 [00:01<00:00, 242.55it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 66:  77%|▊| 300/392 [00:01<00:00, 224.56it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  82%|▊| 320/392 [00:01<00:00, 222.48it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 66:  87%|▊| 340/392 [00:01<00:00, 227.71it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 66:  92%|▉| 360/392 [00:01<00:00, 232.50it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 66:  97%|▉| 380/392 [00:01<00:00, 237.65it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 66: 100%|█| 392/392 [00:01<00:00, 238.72it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 67:  77%|▊| 300/392 [00:01<00:00, 223.20it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  82%|▊| 320/392 [00:01<00:00, 215.20it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 67:  87%|▊| 340/392 [00:01<00:00, 220.65it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 67:  92%|▉| 360/392 [00:01<00:00, 224.89it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 67:  97%|▉| 380/392 [00:01<00:00, 221.00it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 67: 100%|█| 392/392 [00:01<00:00, 222.93it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 68:  77%|▊| 300/392 [00:01<00:00, 217.12it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  82%|▊| 320/392 [00:01<00:00, 216.24it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 68:  87%|▊| 340/392 [00:01<00:00, 221.50it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 68:  92%|▉| 360/392 [00:01<00:00, 225.28it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 68:  97%|▉| 380/392 [00:01<00:00, 229.92it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 68: 100%|█| 392/392 [00:01<00:00, 231.94it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 69:  77%|▊| 300/392 [00:01<00:00, 215.05it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 69:  82%|▊| 320/392 [00:01<00:00, 213.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 69:  87%|▊| 340/392 [00:01<00:00, 218.74it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 69:  92%|▉| 360/392 [00:01<00:00, 221.57it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 69:  97%|▉| 380/392 [00:01<00:00, 226.03it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 69: 100%|█| 392/392 [00:01<00:00, 228.53it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 70:  77%|▊| 300/392 [00:01<00:00, 218.01it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70:  82%|▊| 320/392 [00:01<00:00, 214.84it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70:  87%|▊| 340/392 [00:01<00:00, 219.79it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 70:  92%|▉| 360/392 [00:01<00:00, 224.44it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 70:  97%|▉| 380/392 [00:01<00:00, 229.31it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 70: 100%|█| 392/392 [00:01<00:00, 231.60it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 71:  77%|▊| 300/392 [00:01<00:00, 215.81it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  82%|▊| 320/392 [00:01<00:00, 215.83it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 71:  87%|▊| 340/392 [00:01<00:00, 221.21it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 71:  92%|▉| 360/392 [00:01<00:00, 226.38it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 71:  97%|▉| 380/392 [00:01<00:00, 228.54it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 71: 100%|█| 392/392 [00:01<00:00, 230.88it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 72:  77%|▊| 300/392 [00:01<00:00, 219.76it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72:  82%|▊| 320/392 [00:01<00:00, 218.92it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 72:  87%|▊| 340/392 [00:01<00:00, 223.68it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 72:  92%|▉| 360/392 [00:01<00:00, 228.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 72:  97%|▉| 380/392 [00:01<00:00, 233.35it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 72: 100%|█| 392/392 [00:01<00:00, 234.44it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 73:  77%|▊| 300/392 [00:01<00:00, 218.06it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  82%|▊| 320/392 [00:01<00:00, 216.88it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 73:  87%|▊| 340/392 [00:01<00:00, 222.02it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 73:  92%|▉| 360/392 [00:01<00:00, 226.38it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 73:  97%|▉| 380/392 [00:01<00:00, 230.29it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 73: 100%|█| 392/392 [00:01<00:00, 232.41it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 74:  77%|▊| 300/392 [00:01<00:00, 221.99it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74:  82%|▊| 320/392 [00:01<00:00, 220.94it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 74:  87%|▊| 340/392 [00:01<00:00, 225.30it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 74:  92%|▉| 360/392 [00:01<00:00, 230.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 74:  97%|▉| 380/392 [00:01<00:00, 234.59it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 74: 100%|█| 392/392 [00:01<00:00, 236.55it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 75:  77%|▊| 300/392 [00:01<00:00, 224.42it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75:  82%|▊| 320/392 [00:01<00:00, 223.48it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 75:  87%|▊| 340/392 [00:01<00:00, 229.03it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 75:  92%|▉| 360/392 [00:01<00:00, 233.85it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 75:  97%|▉| 380/392 [00:01<00:00, 238.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 75: 100%|█| 392/392 [00:01<00:00, 239.68it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 76:  77%|▊| 300/392 [00:01<00:00, 226.22it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  82%|▊| 320/392 [00:01<00:00, 224.97it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 76:  87%|▊| 340/392 [00:01<00:00, 230.30it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 76:  92%|▉| 360/392 [00:01<00:00, 235.49it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 76:  97%|▉| 380/392 [00:01<00:00, 239.55it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 76: 100%|█| 392/392 [00:01<00:00, 241.71it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 77:  77%|▊| 300/392 [00:01<00:00, 223.02it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77:  82%|▊| 320/392 [00:01<00:00, 222.43it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 77:  87%|▊| 340/392 [00:01<00:00, 228.18it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 77:  92%|▉| 360/392 [00:01<00:00, 231.63it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 77:  97%|▉| 380/392 [00:01<00:00, 236.64it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 77: 100%|█| 392/392 [00:01<00:00, 238.68it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 78:  77%|▊| 300/392 [00:01<00:00, 226.43it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78:  82%|▊| 320/392 [00:01<00:00, 225.26it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 78:  87%|▊| 340/392 [00:01<00:00, 230.75it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 78:  92%|▉| 360/392 [00:01<00:00, 235.51it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 78:  97%|▉| 380/392 [00:01<00:00, 240.39it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 78: 100%|█| 392/392 [00:01<00:00, 242.50it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 79:  77%|▊| 300/392 [00:01<00:00, 228.65it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  82%|▊| 320/392 [00:01<00:00, 226.82it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 79:  87%|▊| 340/392 [00:01<00:00, 232.24it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 79:  92%|▉| 360/392 [00:01<00:00, 237.49it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 79:  97%|▉| 380/392 [00:01<00:00, 241.96it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 79: 100%|█| 392/392 [00:01<00:00, 243.56it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 80:  77%|▊| 300/392 [00:01<00:00, 228.47it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  82%|▊| 320/392 [00:01<00:00, 227.07it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 80:  87%|▊| 340/392 [00:01<00:00, 232.64it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 80:  92%|▉| 360/392 [00:01<00:00, 236.51it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 80:  97%|▉| 380/392 [00:01<00:00, 241.13it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 80: 100%|█| 392/392 [00:01<00:00, 242.17it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 81:  77%|▊| 300/392 [00:01<00:00, 222.13it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81:  82%|▊| 320/392 [00:01<00:00, 220.90it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 81:  87%|▊| 340/392 [00:01<00:00, 226.40it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 81:  92%|▉| 360/392 [00:01<00:00, 231.52it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 81:  97%|▉| 380/392 [00:01<00:00, 235.98it/s, loss=4.48, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 81: 100%|█| 392/392 [00:01<00:00, 237.38it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 82:  77%|▊| 300/392 [00:01<00:00, 223.39it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82:  82%|▊| 320/392 [00:01<00:00, 220.78it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 82:  87%|▊| 340/392 [00:01<00:00, 225.92it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 82:  92%|▉| 360/392 [00:01<00:00, 231.21it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 82:  97%|▉| 380/392 [00:01<00:00, 235.62it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 82: 100%|█| 392/392 [00:01<00:00, 237.90it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 83:  77%|▊| 300/392 [00:01<00:00, 225.54it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83:  82%|▊| 320/392 [00:01<00:00, 224.65it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 83:  87%|▊| 340/392 [00:01<00:00, 229.27it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 83:  92%|▉| 360/392 [00:01<00:00, 234.38it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 83:  97%|▉| 380/392 [00:01<00:00, 239.03it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 83: 100%|█| 392/392 [00:01<00:00, 241.07it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 84:  77%|▊| 300/392 [00:01<00:00, 227.30it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84:  82%|▊| 320/392 [00:01<00:00, 226.15it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 84:  87%|▊| 340/392 [00:01<00:00, 231.64it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 84:  92%|▉| 360/392 [00:01<00:00, 236.96it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 84:  97%|▉| 380/392 [00:01<00:00, 241.84it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 84: 100%|█| 392/392 [00:01<00:00, 243.95it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 85:  77%|▊| 300/392 [00:01<00:00, 226.29it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85:  82%|▊| 320/392 [00:01<00:00, 225.33it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 85:  87%|▊| 340/392 [00:01<00:00, 230.86it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 85:  92%|▉| 360/392 [00:01<00:00, 235.85it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 85:  97%|▉| 380/392 [00:01<00:00, 240.37it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 85: 100%|█| 392/392 [00:01<00:00, 242.56it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 86:  77%|▊| 300/392 [00:01<00:00, 224.84it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86:  82%|▊| 320/392 [00:01<00:00, 224.14it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 86:  87%|▊| 340/392 [00:01<00:00, 229.12it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 86:  92%|▉| 360/392 [00:01<00:00, 234.19it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 86:  97%|▉| 380/392 [00:01<00:00, 239.16it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 86: 100%|█| 392/392 [00:01<00:00, 241.16it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 87:  77%|▊| 300/392 [00:01<00:00, 224.25it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  82%|▊| 320/392 [00:01<00:00, 221.97it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 87:  87%|▊| 340/392 [00:01<00:00, 226.90it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 87:  92%|▉| 360/392 [00:01<00:00, 231.71it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 87:  97%|▉| 380/392 [00:01<00:00, 236.07it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 87: 100%|█| 392/392 [00:01<00:00, 237.45it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 88:  77%|▊| 300/392 [00:01<00:00, 224.66it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  82%|▊| 320/392 [00:01<00:00, 223.86it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 88:  87%|▊| 340/392 [00:01<00:00, 228.99it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 88:  92%|▉| 360/392 [00:01<00:00, 233.94it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 88:  97%|▉| 380/392 [00:01<00:00, 239.23it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 88: 100%|█| 392/392 [00:01<00:00, 240.84it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 89:  77%|▊| 300/392 [00:01<00:00, 218.96it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89:  82%|▊| 320/392 [00:01<00:00, 218.71it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 89:  87%|▊| 340/392 [00:01<00:00, 223.30it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 89:  92%|▉| 360/392 [00:01<00:00, 228.38it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 89:  97%|▉| 380/392 [00:01<00:00, 232.30it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 89: 100%|█| 392/392 [00:01<00:00, 234.77it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 90:  77%|▊| 300/392 [00:01<00:00, 225.30it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90:  82%|▊| 320/392 [00:01<00:00, 224.91it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 90:  87%|▊| 340/392 [00:01<00:00, 229.93it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 90:  92%|▉| 360/392 [00:01<00:00, 235.00it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 90:  97%|▉| 380/392 [00:01<00:00, 237.85it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 90: 100%|█| 392/392 [00:01<00:00, 237.57it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 91:  77%|▊| 300/392 [00:01<00:00, 226.09it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 91:  82%|▊| 320/392 [00:01<00:00, 225.79it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 91:  87%|▊| 340/392 [00:01<00:00, 230.09it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 91:  92%|▉| 360/392 [00:01<00:00, 234.21it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 91:  97%|▉| 380/392 [00:01<00:00, 238.17it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 91: 100%|█| 392/392 [00:01<00:00, 240.52it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 92:  77%|▊| 300/392 [00:01<00:00, 228.72it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92:  82%|▊| 320/392 [00:01<00:00, 227.36it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 92:  87%|▊| 340/392 [00:01<00:00, 232.65it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 92:  92%|▉| 360/392 [00:01<00:00, 237.48it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 92:  97%|▉| 380/392 [00:01<00:00, 241.77it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 92: 100%|█| 392/392 [00:01<00:00, 243.27it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 93:  77%|▊| 300/392 [00:01<00:00, 225.97it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93:  82%|▊| 320/392 [00:01<00:00, 224.69it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 93:  87%|▊| 340/392 [00:01<00:00, 228.49it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 93:  92%|▉| 360/392 [00:01<00:00, 233.34it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 93:  97%|▉| 380/392 [00:01<00:00, 236.39it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 93: 100%|█| 392/392 [00:01<00:00, 237.91it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94:  77%|▊| 300/392 [00:01<00:00, 228.85it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 94:  82%|▊| 320/392 [00:01<00:00, 227.17it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 94:  87%|▊| 340/392 [00:01<00:00, 232.57it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 94:  92%|▉| 360/392 [00:01<00:00, 237.66it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 94:  97%|▉| 380/392 [00:01<00:00, 241.87it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 94: 100%|█| 392/392 [00:01<00:00, 244.11it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 95:  77%|▊| 300/392 [00:01<00:00, 223.58it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95:  82%|▊| 320/392 [00:01<00:00, 222.53it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 95:  87%|▊| 340/392 [00:01<00:00, 227.54it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 95:  92%|▉| 360/392 [00:01<00:00, 232.90it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 95:  97%|▉| 380/392 [00:01<00:00, 238.00it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 95: 100%|█| 392/392 [00:01<00:00, 240.25it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 96:  77%|▊| 300/392 [00:01<00:00, 176.06it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 96:  82%|▊| 320/392 [00:01<00:00, 178.57it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 96:  87%|▊| 340/392 [00:01<00:00, 184.94it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 96:  92%|▉| 360/392 [00:01<00:00, 189.17it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 96:  97%|▉| 380/392 [00:02<00:00, 188.02it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 96: 100%|█| 392/392 [00:02<00:00, 189.89it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 97:  77%|▊| 300/392 [00:01<00:00, 196.10it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97:  82%|▊| 320/392 [00:01<00:00, 198.40it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 97:  87%|▊| 340/392 [00:01<00:00, 203.61it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 97:  92%|▉| 360/392 [00:01<00:00, 207.83it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 97:  97%|▉| 380/392 [00:01<00:00, 212.83it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 97: 100%|█| 392/392 [00:01<00:00, 215.11it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 98:  77%|▊| 300/392 [00:01<00:00, 174.14it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98:  82%|▊| 320/392 [00:01<00:00, 177.30it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 98:  87%|▊| 340/392 [00:01<00:00, 184.33it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 98:  92%|▉| 360/392 [00:01<00:00, 191.25it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 98:  97%|▉| 380/392 [00:01<00:00, 197.70it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 98: 100%|█| 392/392 [00:01<00:00, 201.25it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 99:  77%|▊| 300/392 [00:02<00:00, 116.95it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99:  82%|▊| 320/392 [00:02<00:00, 119.49it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 99:  87%|▊| 340/392 [00:02<00:00, 124.33it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 99:  92%|▉| 360/392 [00:02<00:00, 128.89it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 99:  97%|▉| 380/392 [00:02<00:00, 132.49it/s, loss=4.47, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 99: 100%|█| 392/392 [00:02<00:00, 134.45it/s, loss=4.42, v_num=0, val_loss=4.490, tr\u001b[A\n",
      "Epoch 100:  77%|▊| 300/392 [00:01<00:00, 176.95it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 100:  82%|▊| 320/392 [00:01<00:00, 180.31it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 100:  87%|▊| 340/392 [00:01<00:00, 187.38it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 100:  92%|▉| 360/392 [00:01<00:00, 193.95it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 100:  97%|▉| 380/392 [00:01<00:00, 200.01it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 100: 100%|█| 392/392 [00:01<00:00, 203.41it/s, loss=4.42, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 101:  77%|▊| 300/392 [00:01<00:00, 167.30it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 101:  82%|▊| 320/392 [00:01<00:00, 168.64it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 101:  87%|▊| 340/392 [00:01<00:00, 174.32it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 101:  92%|▉| 360/392 [00:02<00:00, 179.94it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 101:  97%|▉| 380/392 [00:02<00:00, 185.35it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 101: 100%|█| 392/392 [00:02<00:00, 188.31it/s, loss=4.42, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 102:  77%|▊| 300/392 [00:02<00:00, 116.42it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 102:  82%|▊| 320/392 [00:02<00:00, 120.21it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 102:  87%|▊| 340/392 [00:02<00:00, 125.81it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 102:  92%|▉| 360/392 [00:02<00:00, 131.17it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 102:  97%|▉| 380/392 [00:02<00:00, 136.46it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 102: 100%|█| 392/392 [00:02<00:00, 139.46it/s, loss=4.42, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 103:  77%|▊| 300/392 [00:01<00:00, 185.17it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 103:  82%|▊| 320/392 [00:01<00:00, 186.20it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 103:  87%|▊| 340/392 [00:01<00:00, 192.68it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 103:  92%|▉| 360/392 [00:01<00:00, 199.07it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 103:  97%|▉| 380/392 [00:01<00:00, 205.18it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 103: 100%|█| 392/392 [00:01<00:00, 208.47it/s, loss=4.42, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 104:  77%|▊| 300/392 [00:01<00:00, 218.01it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 104:  82%|▊| 320/392 [00:01<00:00, 220.63it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 104:  87%|▊| 340/392 [00:01<00:00, 228.07it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 104:  92%|▉| 360/392 [00:01<00:00, 234.93it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 104:  97%|▉| 380/392 [00:01<00:00, 241.10it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 104: 100%|█| 392/392 [00:01<00:00, 243.86it/s, loss=4.42, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 105:  77%|▊| 300/392 [00:01<00:00, 211.04it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                  | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 105:  82%|▊| 320/392 [00:01<00:00, 211.25it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 105:  87%|▊| 340/392 [00:01<00:00, 215.95it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 105:  92%|▉| 360/392 [00:01<00:00, 220.47it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105:  97%|▉| 380/392 [00:01<00:00, 224.20it/s, loss=4.47, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 105: 100%|█| 392/392 [00:01<00:00, 225.14it/s, loss=4.42, v_num=0, val_loss=4.490, t\u001b[A\n",
      "Epoch 105: 100%|█| 392/392 [00:01<00:00, 221.14it/s, loss=4.42, v_num=0, val_loss=4.490, t\u001b[A\n"
     ]
    }
   ],
   "source": [
    "system, trainer = train(\n",
    "    SigmoidNet,\n",
    "    OmegaConf.to_container(config),\n",
    "    experiment_dir=bigboy.data_path,\n",
    "    checkpoint_name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b4d3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearEmbedder(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.05)\n",
      "    (2): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.05)\n",
      "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.05)\n",
      "    (6): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "LinearEmbedder(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.05)\n",
      "    (2): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.05)\n",
      "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.05)\n",
      "    (6): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "X_fname = f\"{bigboy.data_path}/modeling_features.npy\"\n",
    "model_fname = f\"{bigboy.data_path}/{expt_name}/model-v1.ckpt\"\n",
    "system = SigmoidNet(config)\n",
    "\n",
    "model = system.load_from_checkpoint(model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94ecc2",
   "metadata": {},
   "source": [
    "0.9 prew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fbc922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49945, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_embedded_mse = torch.squeeze(model(torch.unsqueeze(torch.from_numpy(np.load(X_fname)).float(), 1))).detach().numpy()\n",
    "print(X_embedded_mse.shape)\n",
    "\n",
    "plt.figure()\n",
    "mse_boundary = 24945\n",
    "\n",
    "mf = plt.scatter(X_embedded_mse[:mse_boundary, 0], X_embedded_mse[:mse_boundary, 1], color='blue', s=20)\n",
    "mb = plt.scatter(X_embedded_mse[mse_boundary:, 0], X_embedded_mse[mse_boundary:, 1], color='red', s=10)\n",
    "\n",
    "plt.legend((mf, mb), ('Synth MF', 'Synth MB'), loc='upper right')\n",
    "\n",
    "border = -0.25\n",
    "plt.vlines(border, -.55, -.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529101cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"% of MF that are over:\", np.sum(X_embedded_mse[:mse_boundary, 1] > border) / X_embedded_mse[:mse_boundary, 1].size)\n",
    "print(\"% of MB that are under:\", np.sum(X_embedded_mse[mse_boundary:, 1] < border) / X_embedded_mse[mse_boundary:, 1].size)\n",
    "\n",
    "print(\"% of over that are MF:\",np.sum(X_embedded_mse[:mse_boundary, 1] > border) / np.sum(X_embedded_mse[:, 1] > border))\n",
    "print(\"% of under that are MB:\",np.sum(X_embedded_mse[mse_boundary:, 1] < border) / np.sum(X_embedded_mse[:, 1] < border))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47c3fc",
   "metadata": {},
   "source": [
    "1.0 prew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba62c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_mse = torch.squeeze(model(torch.unsqueeze(torch.from_numpy(np.load(X_fname)).float(), 1))).detach().numpy()\n",
    "print(X_embedded_mse.shape)\n",
    "\n",
    "plt.figure()\n",
    "mse_boundary = 42171\n",
    "\n",
    "# X_embedded_mse = normalize_features(X_embedded_mse)\n",
    "\n",
    "mf = plt.scatter(X_embedded_mse[:mse_boundary, 0], X_embedded_mse[:mse_boundary, 1], color='blue', s=20)\n",
    "mb = plt.scatter(X_embedded_mse[mse_boundary:, 0], X_embedded_mse[mse_boundary:, 1], color='red', s=10)\n",
    "# real = plt.scatter(X_embedded_mse[mse_boundary1:, 0], X_embedded_mse[mse_boundary1:, 1], color='yellow', s=5)\n",
    "\n",
    "borders = [-0.585, -0.57, -0.555, -0.51, -0.45, -0.35, -0.277]\n",
    "plt.legend((mf, mb), ('Synth MF', 'Synth MB'), loc='upper right')\n",
    "plt.vlines(borders, -0.6, 0, color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5242ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"% of MF that are left:\", np.sum(X_embedded_mse[:mse_boundary, 0] < border) / X_embedded_mse[:mse_boundary, 0].size)\n",
    "print(\"% of MB that are right:\", np.sum(X_embedded_mse[mse_boundary:, 0] > border) / X_embedded_mse[mse_boundary:, 0].size)\n",
    "\n",
    "print(\"% of left that are MF:\",np.sum(X_embedded_mse[:mse_boundary, 0] < border) / np.sum(X_embedded_mse[:, 0] < border))\n",
    "print(\"% of right that are MB:\",np.sum(X_embedded_mse[mse_boundary:, 0] > border) / np.sum(X_embedded_mse[:, 0] > border))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "mse_boundary = 42171\n",
    "\n",
    "mf = plt.scatter(X_embedded_mse[:mse_boundary, 0], X_embedded_mse[:mse_boundary, 1], color='blue', s=15)\n",
    "mb = plt.scatter(X_embedded_mse[mse_boundary:, 0], X_embedded_mse[mse_boundary:, 1], color='red', s=10)\n",
    "# real = plt.scatter(X_embedded_mse[mse_boundary1:, 0], X_embedded_mse[mse_boundary1:, 1], color='yellow', s=5)\n",
    "\n",
    "plt.legend((mf, mb), ('Synth MF', 'Synth MB'), loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
